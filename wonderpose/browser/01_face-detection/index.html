<!-- Based on this: https://github.com/tensorflow/tfjs-models/tree/master/face-landmarks-detection -->
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
  </head>
  <body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.js"></script>
    <!-- Require the peer dependencies of face-landmarks-detection. -->
    <script src="https://unpkg.com/@tensorflow/tfjs-core@2.4.0/dist/tf-core.js"></script>
    <script src="https://unpkg.com/@tensorflow/tfjs-converter@2.4.0/dist/tf-converter.js"></script>

    <!-- You must explicitly require a TF.js backend if you're not using the tfjs union bundle. -->
    <script src="https://unpkg.com/@tensorflow/tfjs-backend-cpu@2.4.0/dist/tf-backend-cpu.js"></script>
    <!-- <script src="https://unpkg.com/@tensorflow/tfjs-backend-webgl@2.4.0/dist/tf-backend-webgl.js"></script> -->
    <!-- Alternatively you can use the WASM backend: <script src="https://unpkg.com/@tensorflow/tfjs-backend-wasm@2.4.0/dist/tf-backend-wasm.js"></script> -->

    <!-- Require face-landmarks-detection itself. -->
    <script src="https://unpkg.com/@tensorflow-models/face-landmarks-detection@0.0.1/dist/face-landmarks-detection.js"></script>
    <script>
      const images = ['../../assets/face1.png', '../../assets/face2.jpg', '../../assets/face3.jpg'];

      const data = [];

      async function main() {
        for (let imgI = 0; imgI < images.length; imgI += 1) {
          // Load the MediaPipe Facemesh package.
          const model = await faceLandmarksDetection.load(
            faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);

          await new Promise((resolve, reject) => {
            const image = images[imgI];
            const imgEl = document.createElement("img");
            imgEl.onload = async () => {
              const predictions = await model.estimateFaces({ 
                input: imgEl
              });

              data.push({
                image,
                predictions
              });

              if (predictions.length > 0) {
                // Using p5js to draw the face    
                const sketch = (p) => {
                  let img;
                  p.preload = () => {
                    img = p.loadImage(image);
                  };
                  p.setup = () => {
                    // we only expect one face!
                    const prediction = predictions[0];
                    const keypoints = prediction.scaledMesh;
                    const bounds = prediction.boundingBox;

                    const faceWidth = bounds['bottomRight'][0] - bounds['topLeft'][0];
                    const faceHeight = bounds['bottomRight'][1] - bounds['topLeft'][1];

                    const faceX = bounds['topLeft'][0];
                    const faceY = bounds['topLeft'][1];

                    p.createCanvas(faceWidth, faceHeight);

                    const face = img.get(faceX, faceY, faceWidth, faceHeight);

                    p.image(face, 0, 0);

                    for (let i = 0; i < predictions.length; i++) {
                      p.noFill();
                      p.stroke('red');
                      p.strokeWeight(3);

                      for (let i = 0; i < keypoints.length; i++) {
                        const [x, y, z] = keypoints[i];
                        p.point(x - faceX, y - faceY);
                      }
                    }

                    p.noLoop();
                  };
                };
                new p5(sketch);
              }
              resolve();
            };
            imgEl.src = image;
          });
        }
        // const a = document.createElement("a");
        // const file = new Blob([JSON.stringify(data)], {type: 'application/json'});
        // a.href = URL.createObjectURL(file);
        // a.download = 'data.json';
        // a.click();
      }

      main();
    </script>
  </body>
</html>
